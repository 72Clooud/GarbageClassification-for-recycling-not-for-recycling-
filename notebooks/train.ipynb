{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available: NVIDIA GeForce RTX 2060\n"
     ]
    }
   ],
   "source": [
    "if device.type == \"cuda\":\n",
    "    print(f\"GPU is available: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"GPU is not available, using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data_dir: str, categories: List[str], transform = None):\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "\n",
    "        for idx, category in enumerate(categories):\n",
    "            category_path = os.path.join(data_dir, category)\n",
    "            for file_name in tqdm(os.listdir(category_path), desc=f\"Loading category: {category}\", unit=\"file\"):\n",
    "                file_path = os.path.join(category_path, file_name)\n",
    "                self.data.append(file_path)\n",
    "                self.labels.append(idx)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        img_path = self.data[index]\n",
    "        label = self.labels[index]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    \n",
    "    def __init__(self, data_dir: str, train_dir: str, test_dir: str, val_dir: str, categories: List[str]):\n",
    "        self.data_dir = data_dir\n",
    "        self.train_dir = train_dir\n",
    "        self.test_dir = test_dir\n",
    "        self.val_dir = val_dir\n",
    "        self.categories = categories\n",
    "        \n",
    "    def split_data(self, test_size=0.2, val_size=0.2) -> None:\n",
    "        for category in self.categories:\n",
    "            category_path = os.path.join(self.data_dir, category)\n",
    "            images = os.listdir(category_path)\n",
    "            \n",
    "            train_val_images, test_images = train_test_split(images, test_size=test_size)\n",
    "            train_images, val_images = train_test_split(train_val_images, test_size=val_size / (1 - test_size))\n",
    "            \n",
    "            os.makedirs(os.path.join(self.train_dir, category), exist_ok=True)\n",
    "            os.makedirs(os.path.join(self.test_dir, category), exist_ok=True)\n",
    "            os.makedirs(os.path.join(self.val_dir, category), exist_ok=True)\n",
    "            \n",
    "            for image in tqdm(train_images, desc=f\"Copying train images for {category}\", unit=\"image\"):\n",
    "                shutil.copyfile(os.path.join(category_path, image), os.path.join(self.train_dir, category, image))\n",
    "            for image in tqdm(test_images, desc=f\"Copying test images for {category}\", unit=\"image\"):\n",
    "                shutil.copyfile(os.path.join(category_path, image), os.path.join(self.test_dir, category, image))\n",
    "            for image in tqdm(val_images, desc=f\"Copying val images for {category}\", unit=\"image\"):\n",
    "                shutil.copyfile(os.path.join(category_path, image), os.path.join(self.val_dir, category, image))\n",
    "                \n",
    "    def create_data_loader(self, batch_size=64, test_batch_size=32):\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        \n",
    "        train_dataset = CustomDataset(self.train_dir, self.categories, transform)\n",
    "        test_dataset = CustomDataset(self.test_dir, self.categories, transform)\n",
    "        val_dataset = CustomDataset(self.val_dir, self.categories, transform)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "        \n",
    "        return train_loader, test_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelHandler:\n",
    "    \n",
    "    def __init__(self, num_classes, device):\n",
    "        self.device = device\n",
    "        self.model = self._create_model(num_classes)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=1e-3)\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode='max', patience=5, factor=0.1)\n",
    "    \n",
    "    def _create_model(self, num_classes):\n",
    "        model = models.efficientnet_v2_s(weights=models.EfficientNet_V2_S_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Linear(model.classifier[1].in_features, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.08),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "        \n",
    "        for param in model.features.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        return model.to(self.device)\n",
    "    \n",
    "    def train_one_epoch(self, dataloader):\n",
    "        self.model.train()\n",
    "        epoch_loss, correct = 0.0, 0\n",
    "        \n",
    "        for images, labels in tqdm(dataloader, desc=\"Training\", unit=\"batch\"):\n",
    "            images, labels = images.to(self.device), labels.to(self.device)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(images)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item() * images.size(0)\n",
    "            correct += (outputs.argmax(1) == labels).sum().item()\n",
    "        \n",
    "        epoch_loss /= len(dataloader.dataset)\n",
    "        accuracy = correct / len(dataloader.dataset)\n",
    "        \n",
    "        return epoch_loss, accuracy\n",
    "\n",
    "    def validate(self, dataloader):\n",
    "        self.model.eval()\n",
    "        epoch_loss, correct = 0.0, 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(dataloader, desc=\"Validation\", unit=\"batch\"):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                output = self.model(images)\n",
    "                loss = self.criterion(output, labels)\n",
    "                \n",
    "                epoch_loss += loss.item() * images.size(0)\n",
    "                correct += (output.argmax(1) == labels).sum().item()\n",
    "            \n",
    "        epoch_loss /= len(dataloader.dataset)\n",
    "        accuracy = correct / len(dataloader.dataset)\n",
    "        \n",
    "        return epoch_loss, accuracy\n",
    "    \n",
    "    def train_model(self, train_loader, val_loader, num_epochs):\n",
    "        best_acc = 0.0\n",
    "        history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            train_loss, train_acc = self.train_one_epoch(train_loader)\n",
    "            val_loss, val_acc = self.validate(val_loader)\n",
    "            \n",
    "            self.scheduler.step(val_acc)\n",
    "            \n",
    "            history['train_loss'].append(train_loss)\n",
    "            history['train_acc'].append(train_acc)\n",
    "            history['val_loss'].append(val_loss)\n",
    "            history['val_acc'].append(val_acc)\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}: \"\n",
    "                  f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "                  f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "            \n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                self.save_model('../models/best_model.pth')\n",
    "\n",
    "        return history\n",
    "    \n",
    "    def save_model(self, path):\n",
    "        torch.save(self.model.state_dict(), path)\n",
    "        \n",
    "    def load_model(self, path):\n",
    "        self.model.load_state_dict(torch.load(path))\n",
    "        self.model.to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    categories = ['battery', 'biological', 'brown-glass', 'cardboard', 'clothes',\n",
    "                  'green-glass', 'metal', 'paper', 'plastic', 'shoes', 'trash', 'white-glass']\n",
    "\n",
    "    data_processor = DataProcessor('../data', '../train_dir', '../test_dir', '../val_dir', categories)\n",
    "    data_processor.split_data()\n",
    "    \n",
    "    train_loader, test_loader = data_processor.create_data_loader()\n",
    "    \n",
    "    model_handler = ModelHandler(num_classes=len(categories),device=device)\n",
    "    \n",
    "    history = model_handler.train_model(train_loader, test_loader, 25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
